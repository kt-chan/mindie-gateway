# .env file for vLLM configuration
#VLLM_MODEL=Qwen/Qwen3-4B
#REASONING_PARSER=qwen3
VLLM_MODEL=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
REASONING_PARSER=deepseek_r1
VLLM_HOST=0.0.0.0
VLLM_PORT=8000
GPU_MEMORY_UTILIZATION=0.85
MAX_MODEL_LEN=4096
MAX_NUM_SEQS=8
#MAX_NUM_BATCHED_TOKENS=4096
MAX_NUM_BATCHED_TOKENS=32768
# AUTH_SERVICE
AUTH_SERVICE_HOST=127.0.0.1
AUTH_SERVICE_PORT=8020